{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBC News Headlines: Building FTS5 + `vec0` indexes\n",
    "\n",
    "Using the dataset built in [the previous `./1_scrape.ipynb` notebook](./1_scrape.ipynb), \n",
    "this notebook will enrich that dataset with a full-text search index and a semantic search index,\n",
    "using  [FTS5](https://www.sqlite.org/fts5.html), \n",
    "[`sqlite-vec`](https://github.com/asg017/sqlite-vec), and \n",
    "[`sqlite-lembed`](https://github.com/asg017/sqlite-lembed).\n",
    "\n",
    "This example will use pure SQL for everything. You can do the same exact thing in Python/JavaScript/Go/Rust/etc., or use\n",
    "your own embeddings providers like Ollama/llamafile/OpenAI/etc. The core mechanics of FTS5 and `sqlite-vec` will remain the same. \n",
    "\n",
    "We will use the [Snowflake Artic Embed v1.5](https://huggingface.co/Snowflake/snowflake-arctic-embed-m-v1.5) embeddings model to generate embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "Expression expected at file:///repl.tsx:1:1\n\n  .open headlines-2024.db\n  ~",
     "evalue": "Expression expected at file:///repl.tsx:1:1\n\n  .open headlines-2024.db\n  ~",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    ".open headlines-2024.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Create a FTS5 index\n",
    "\n",
    "Creating a full-text search index is as simple as 3 SQL commands! We already have the headlines stored in the `articles` \n",
    "table under the `headline` column, so it's just a matter of initializing the FTS5 virtual table and inserting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "Expected ';', '}' or <eof> at file:///repl.tsx:1:8\n\n  create virtual table fts_articles using fts5(\n         ~~~~~~~",
     "evalue": "Expected ';', '}' or <eof> at file:///repl.tsx:1:8\n\n  create virtual table fts_articles using fts5(\n         ~~~~~~~",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "create virtual table fts_articles using fts5(\n",
    "  headline,\n",
    "  content='articles', content_rowid='id'\n",
    ");\n",
    "\n",
    "insert into fts_articles(rowid, headline)\n",
    "  select rowid, headline\n",
    "  from articles;\n",
    "\n",
    "insert into fts_articles(fts_articles) values('optimize');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By convention we name the FTS5 table `fts_articles`, where the `fts_` prefix says \"this virtual table is full-text search of the `articles` table\". We are only searching the `headline` column, the rest can be ignored. \n",
    "\n",
    "Here we are using the [\"external content tables\"](https://www.sqlite.org/fts5.html#external_content_tables)\n",
    "feature in FTS5 tables, which will avoid storing the headlines a 2nd time, since they already exist in the `articles` table. \n",
    "This part isn't required, but saves us a bit of storage. \n",
    "\n",
    "We also use the [`'optimize'`](https://www.sqlite.org/fts5.html#the_optimize_command) command\n",
    " to keep things tidy. This doesn't do much on such a small dataset, but is important to remember for larger tables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "Expected ';', '}' or <eof> at file:///repl.tsx:2:6\n\n  from fts_articles\n       ~~~~~~~~~~~~",
     "evalue": "Expected ';', '}' or <eof> at file:///repl.tsx:2:6\n\n  from fts_articles\n       ~~~~~~~~~~~~",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "select *\n",
    "from fts_articles\n",
    "where headline match 'planned parenthood'\n",
    "limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create a \"semantic index\"\n",
    "\n",
    "\"Semantic index\" in this case is just a fancy way of saying \"vector store\", which we will do with a `sqlite-vec` `vec0` virtual table. \n",
    "\n",
    "Now, `sqlite-vec` just stores vectors, it doesn't generate embeddings for us. There are hundreds of different remote APIs or local inference runtimes you can use to generate embeddings,\n",
    "but here we will use [`sqlite-lembed`](https://github.com/asg017/sqlite-lembed) to keep everything local and everything in pure SQL. \n",
    "\n",
    "We will need to choose an embeddings model in the [GGUF format](https://huggingface.co/docs/hub/en/gguf),\n",
    "since `sqlite-lembed` uses [llama.cpp](https://github.com/ggerganov/llama.cpp) under the hood. \n",
    "Here we will use [`Snowflake/snowflake-arctic-embed-m-v1.5`](https://huggingface.co/Snowflake/snowflake-arctic-embed-m-v1.5),\n",
    "where we can find a GGUF version [here](https://huggingface.co/asg017/sqlite-lembed-model-examples/tree/main/snowflake-arctic-embed-m-v1.5). \n",
    "This model is small-sh (`436MB` full-sized, `118MB` at `Q8_0` quantized), and is trained on fairly recent data so it understands\n",
    "recent events like \"COVID-19\" or \"Kamala Harris\". \n",
    "\n",
    "You can download a `.gguf` quantized version of this model with:\n",
    "\n",
    "```bash\n",
    "wget https://huggingface.co/asg017/sqlite-lembed-model-examples/resolve/main/snowflake-arctic-embed-m-v1.5/snowflake-arctic-embed-m-v1.5.d70deb40.f16.gguf\n",
    "```\n",
    "\n",
    "And we can configure `sqlite-lembed` to use this model like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Expression expected at file:///repl.tsx:1:1\n\n  .load ./lembed0\n  ~",
     "evalue": "Expression expected at file:///repl.tsx:1:1\n\n  .load ./lembed0\n  ~",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    ".load ./lembed0\n",
    ".load ../../dist/vec0\n",
    "\n",
    "insert into lembed_models(name, model) values\n",
    "  ('default', lembed_model_from_file('./snowflake-arctic-embed-m-v1.5.d70deb40.f16.gguf'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's embeddings time! We can use the `lembed()` function, which takes in text and returns a vector representation of that text,\n",
    "as an embeddings BLOB that we can insert directly into a `vec0` virtul table. \n",
    "\n",
    "We'll declare this new `vec_articles` table, using the `vec_` prefix as convention. This matches the `fts_articles` table above. \n",
    "The Snowflake embedding model generate vectors with `768` dimensions, which we we store as-as. \n",
    "\n",
    "Embedding and inserting into this vector store is as easy as a single `INSERT INTO` and `lembed()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "Expected ';', '}' or <eof> at file:///repl.tsx:2:8\n\n  create virtual table vec_articles using vec0(\n         ~~~~~~~",
     "evalue": "Expected ';', '}' or <eof> at file:///repl.tsx:2:8\n\n  create virtual table vec_articles using vec0(\n         ~~~~~~~",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "\n",
    "create virtual table vec_articles using vec0(\n",
    "  article_id integer primary key,\n",
    "  headline_embedding float[768]\n",
    ");\n",
    "\n",
    "insert into vec_articles(article_id, headline_embedding)\n",
    "select\n",
    "  rowid,\n",
    "  lembed(headline)\n",
    "from articles;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took ~13 minutes for ~14,500 embeddings on my older 2019 Macbook, but newer computers with better CPUs will finish quicker (it took `2m20s` on my newer Mac M1 Mini). \n",
    "\n",
    "Once the `vec_articles` is ready, we can perform a KNN query like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Expected ';', '}' or <eof> at file:///repl.tsx:4:6\n\n  from vec_articles\n       ~~~~~~~~~~~~",
     "evalue": "Expected ';', '}' or <eof> at file:///repl.tsx:4:6\n\n  from vec_articles\n       ~~~~~~~~~~~~",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "select\n",
    "  articles.headline,\n",
    "  vec_articles.distance\n",
    "from vec_articles\n",
    "left join articles on articles.rowid = vec_articles.article_id\n",
    "where headline_embedding match lembed(\"planned parenthood\")\n",
    "  and k = 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slim it down with Binary Quantization\n",
    "\n",
    "The vectors in the `vec_articles` table take up a lot of space. A vector with `768` dimensions take up `786 * 4 = 3072` bytes of space each, or around `45MB` of space for these ~14,500 entries. \n",
    "\n",
    "That's a lot â€” the original text dataset was only `~4MB`!\n",
    "\n",
    "If you want to make the database smaller, there's a number of quantization or other methods to do so, by trading accuracy. \n",
    "Here's an example of performing [binary quantization](https://alexgarcia.xyz/sqlite-vec/guides/binary-quant.html)\n",
    "on this dataset, storing 768-dimensional bit-vectors instead of floating-point vectors, a `32x` size reduction, at the expense of accuracy. \n",
    "\n",
    "We'll keep the current SQLite database as-is, and instead make a copy into a new SQLite database file, and change the `vec_articles` table\n",
    "to store bit-vectors instead. \n",
    "\n",
    "First, we'll make a copy of the current database into a new file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "Expected ';', '}' or <eof> at file:///repl.tsx:1:8\n\n  vacuum into 'tmp-artic2.slim.db';\n         ~~~~",
     "evalue": "Expected ';', '}' or <eof> at file:///repl.tsx:1:8\n\n  vacuum into 'tmp-artic2.slim.db';\n         ~~~~",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "vacuum into 'tmp-artic2.slim.db';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll make a connection to this new file, and drop the old `vec_articles` table that contains the large `float[768]` vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "Expected ';', '}' or <eof> at file:///repl.tsx:1:8\n\n  attach database 'tmp-artic2.slim.db' as slim;\n         ~~~~~~~~",
     "evalue": "Expected ';', '}' or <eof> at file:///repl.tsx:1:8\n\n  attach database 'tmp-artic2.slim.db' as slim;\n         ~~~~~~~~",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "attach database 'tmp-artic2.slim.db' as slim;\n",
    "drop table slim.vec_articles;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a new `vec0` table, storing `bit[768]` vectors instead! \n",
    "We can insert the original `float[768]` from the `main.vec_articles` table (original table),\n",
    "calling [`vec_quantize_binary()`](https://alexgarcia.xyz/sqlite-vec/api-reference.html#vec_quantize_binary) to convert the floats to bits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "Expected ';', '}' or <eof> at file:///repl.tsx:2:8\n\n  create virtual table slim.vec_articles using vec0(\n         ~~~~~~~",
     "evalue": "Expected ';', '}' or <eof> at file:///repl.tsx:2:8\n\n  create virtual table slim.vec_articles using vec0(\n         ~~~~~~~",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "\n",
    "create virtual table slim.vec_articles using vec0(\n",
    "  article_id integer primary key,\n",
    "  headline_embedding bit[768]\n",
    ");\n",
    "\n",
    "insert into slim.vec_articles(article_id, headline_embedding)\n",
    "select\n",
    "  article_id,\n",
    "  vec_quantize_binary(headline_embedding)\n",
    "from main.vec_articles;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can `VACUUM` the new `slim` database to shrink the file, delete the `DROP`'ed pages from the older `vec0` table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "Expected ';', '}' or <eof> at file:///repl.tsx:1:8\n\n  vacuum slim;\n         ~~~~",
     "evalue": "Expected ';', '}' or <eof> at file:///repl.tsx:1:8\n\n  vacuum slim;\n         ~~~~",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "vacuum slim;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there we have it! This file is `7.1MB`, a large reduction from the original `53MB` table. \n",
    "\n",
    "KNN queries are similar, only adding the `vec_quantize_binary()` function to the query vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "Expected ';', '}' or <eof> at file:///repl.tsx:4:6\n\n  from slim.vec_articles\n       ~~~~",
     "evalue": "Expected ';', '}' or <eof> at file:///repl.tsx:4:6\n\n  from slim.vec_articles\n       ~~~~",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "select\n",
    "  slim.articles.headline,\n",
    "  slim.vec_articles.distance\n",
    "from slim.vec_articles\n",
    "left join slim.articles on slim.articles.rowid = slim.vec_articles.article_id\n",
    "where headline_embedding match vec_quantize_binary(lembed(\"planned parenthood\"))\n",
    "  and k = 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice the results differ slightly to the full-sized query from above. Some results are ordered differently, some are missing. \n",
    "The `distance` in this binary KNN search is hamming distance, not the default L2 distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
